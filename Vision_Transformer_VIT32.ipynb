{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vision_Transformer_VIT32.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOTywV8tHEBqzz8qG8Q/EBx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tasfia48/vis_rep_prog_comprehension_project_795/blob/main/Vision_Transformer_VIT32.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Libraries and Configurations"
      ],
      "metadata": {
        "id": "MPmvB3nR0yiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpvwvLYa75q6",
        "outputId": "a3a9bf83-5889-4126-8f38-ce0854eecaee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 31.4 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 31.0 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 16.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 143 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 194 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 225 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 256 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 276 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 286 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 307 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 337 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 358 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 368 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 389 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 399 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 430 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 440 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 450 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 460 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 471 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 481 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 501 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 512 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 522 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 532 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 542 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 552 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 563 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 573 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 583 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 604 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 614 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 624 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 634 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 645 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 655 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 675 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 686 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 696 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 706 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 716 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 727 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 737 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 747 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 757 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 768 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 778 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 788 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 798 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 808 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 819 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 829 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 849 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 860 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 870 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 880 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 890 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 901 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 911 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 921 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 931 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 942 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 952 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 962 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 972 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 983 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 993 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0 MB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0 MB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0 MB 15.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1 MB 15.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1 MB 15.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1 MB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 15.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S3M6qKp76HC",
        "outputId": "5bb2f2fe-5ce4-42e7-b1bc-75e8cef631f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version 2.8.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import glob, warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "print('TensorFlow Version ' + tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Dropout, MaxPooling2D, Flatten"
      ],
      "metadata": {
        "id": "s5HLmyCj7_S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "4nuGhdfa04vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1Cn_hwxJlo1R8I0IDGQcNzPUYtyD6T9a2 #FULL DATASET\n",
        "#!gdown https://drive.google.com/uc?id=18ZKkAW5nPcUOBDeZ3xRjtvErBhAKVKoD #only java csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViYOljBi9L1T",
        "outputId": "f5f97121-5458-439c-9628-be560a497120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Cn_hwxJlo1R8I0IDGQcNzPUYtyD6T9a2\n",
            "To: /content/Readability_Dataset_Complete.zip\n",
            "100% 61.1M/61.1M [00:00<00:00, 91.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'Readability_Dataset_Complete.zip' &>/dev/null"
      ],
      "metadata": {
        "id": "2G5pzkw19QMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Java Only"
      ],
      "metadata": {
        "id": "5qWdRZZk0WGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nsh_dark_java = pd.read_csv('MergedTotal_NSH_Dark/csv/merged_java.csv')\n",
        "nsh_light_java = pd.read_csv('MergedTotal_NSH_Light/csv/merged_java.csv')\n",
        "sh_light_java = pd.read_csv('MergedTotal_SH_Light/csv/merged_java.csv')\n",
        "sh_dark_java = pd.read_csv('MergedTotal_SH_Dark/csv/merged_java.csv')\n",
        "\n",
        "nsh_dark_java['filepaths'] = \"MergedTotal_NSH_Dark/\" + nsh_dark_java['filepaths']\n",
        "nsh_light_java['filepaths'] = \"MergedTotal_NSH_Light/\" + nsh_light_java['filepaths']\n",
        "sh_light_java['filepaths'] = \"MergedTotal_SH_Light/\" + sh_light_java['filepaths']\n",
        "sh_dark_java['filepaths'] = \"MergedTotal_SH_Dark/\" + sh_dark_java['filepaths']\n",
        "\n",
        "train_nsh_dark, val_nsh_dark, test_nsh_dark = \\\n",
        "              np.split(nsh_dark_java.sample(frac=1, random_state=42), \n",
        "                       [int(.8*len(nsh_dark_java)), int(.9*len(nsh_dark_java))])\n",
        "              \n",
        "train_sh_dark, val_sh_dark, test_sh_dark = \\\n",
        "              np.split(sh_dark_java.sample(frac=1, random_state=42), \n",
        "                       [int(.8*len(sh_dark_java)), int(.9*len(sh_dark_java))])\n",
        "\n",
        "train_nsh_light, val_nsh_light, test_nsh_light = \\\n",
        "              np.split(nsh_light_java.sample(frac=1, random_state=42), \n",
        "                       [int(.8*len(nsh_light_java)), int(.9*len(nsh_light_java))])\n",
        "              \n",
        "train_sh_light, val_sh_light, test_sh_light = \\\n",
        "              np.split(sh_light_java.sample(frac=1, random_state=42), \n",
        "                       [int(.8*len(sh_light_java)), int(.9*len(sh_light_java))])\n",
        "              \n",
        "train_df_java = pd.concat([train_nsh_dark,train_sh_dark,train_nsh_light,train_sh_light], ignore_index=True)\n",
        "val_df_java = pd.concat([val_nsh_dark,val_sh_dark,val_nsh_light,val_sh_light], ignore_index=True)\n",
        "test_df_java = pd.concat([test_nsh_dark,test_sh_dark,test_nsh_light,test_sh_light], ignore_index=True)\n",
        "\n",
        "val_df_java['readable'] = val_df_java['readable'].astype(str) \n",
        "train_df_java['readable'] = train_df_java['readable'].astype(str) \n",
        "test_df_java['readable'] = test_df_java['readable'].astype(str) "
      ],
      "metadata": {
        "id": "HjsnovoD9SZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Complete Dataset"
      ],
      "metadata": {
        "id": "FdRW6sJ00iy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nsh_dark_total = pd.read_csv('MergedTotal_NSH_Dark/csv/merged_total.csv')\n",
        "nsh_light_total = pd.read_csv('MergedTotal_NSH_Light/csv/merged_total.csv')\n",
        "sh_light_total = pd.read_csv('MergedTotal_SH_Light/csv/merged_total.csv')\n",
        "sh_dark_total = pd.read_csv('MergedTotal_SH_Dark/csv/merged_total.csv')\n",
        "\n",
        "nsh_dark_total['filepaths'] = \"MergedTotal_NSH_Dark/\" + nsh_dark_total['filepaths']\n",
        "nsh_light_total['filepaths'] = \"MergedTotal_NSH_Light/\" + nsh_light_total['filepaths']\n",
        "sh_light_total['filepaths'] = \"MergedTotal_SH_Light/\" + sh_light_total['filepaths']\n",
        "sh_dark_total['filepaths'] = \"MergedTotal_SH_Dark/\" + sh_dark_total['filepaths']\n",
        "\n",
        "train_nsh_dark, val_nsh_dark, test_nsh_dark = \\\n",
        "              np.split(nsh_dark_total.sample(frac=1, random_state=42), \n",
        "                       [int(.8*len(nsh_dark_total)), int(.9*len(nsh_dark_total))])\n",
        "              \n",
        "train_sh_dark, val_sh_dark, test_sh_dark = \\\n",
        "              np.split(sh_dark_total.sample(frac=1, random_state=42), \n",
        "                       [int(.8*len(sh_dark_total)), int(.9*len(sh_dark_total))])\n",
        "\n",
        "train_nsh_light, val_nsh_light, test_nsh_light = \\\n",
        "              np.split(nsh_light_total.sample(frac=1, random_state=42), \n",
        "                       [int(.8*len(nsh_light_total)), int(.9*len(nsh_light_total))])\n",
        "              \n",
        "train_sh_light, val_sh_light, test_sh_light = \\\n",
        "              np.split(sh_light_total.sample(frac=1, random_state=42), \n",
        "                       [int(.8*len(sh_light_total)), int(.9*len(sh_light_total))])\n",
        "              \n",
        "\n",
        "\n",
        "train_nsh_dark.readable = np.where(train_nsh_dark.average_score >= 3.5, 1, 0)\n",
        "val_nsh_dark.readable = np.where(val_nsh_dark.average_score >= 3.5, 1, 0)\n",
        "test_nsh_dark.readable = np.where(test_nsh_dark.average_score >= 3.5, 1, 0)\n",
        "\n",
        "train_sh_dark.readable = np.where(train_sh_dark.average_score >= 3.5, 1, 0)\n",
        "val_sh_dark.readable = np.where(val_sh_dark.average_score >= 3.5, 1, 0)\n",
        "test_sh_dark.readable = np.where(test_sh_dark.average_score >= 3.5, 1, 0)\n",
        "\n",
        "train_sh_light.readable = np.where(train_sh_light.average_score >= 3.5, 1, 0)\n",
        "val_sh_light.readable = np.where(val_sh_light.average_score >= 3.5, 1, 0)\n",
        "test_sh_light.readable = np.where(test_sh_light.average_score >= 3.5, 1, 0)\n",
        "\n",
        "train_nsh_light.readable = np.where(train_nsh_light.average_score >= 3.5, 1, 0)\n",
        "val_nsh_light.readable = np.where(val_nsh_light.average_score >= 3.5, 1, 0)\n",
        "test_nsh_light.readable = np.where(test_nsh_light.average_score >= 3.5, 1, 0)\n",
        "\n",
        "train_df = pd.concat([train_nsh_dark,train_sh_dark,train_nsh_light,train_sh_light], ignore_index=True)\n",
        "val_df = pd.concat([val_nsh_dark,val_sh_dark,val_nsh_light,val_sh_light], ignore_index=True)\n",
        "test_df = pd.concat([test_nsh_dark,test_sh_dark,test_nsh_light,test_sh_light], ignore_index=True)\n",
        "\n",
        "val_df['readable'] = val_df['readable'].astype(str) \n",
        "train_df['readable'] = train_df['readable'].astype(str) \n",
        "test_df['readable'] = test_df['readable'].astype(str) "
      ],
      "metadata": {
        "id": "eiymKRCh0mM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Generator"
      ],
      "metadata": {
        "id": "j_ExOEEF1LpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 15\n",
        "\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_gen = datagen.flow_from_dataframe(dataframe= train_df,\n",
        "                                        #has_ext=False,\n",
        "                                        x_col='filepaths',\n",
        "                                        y_col='readable',\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        seed=6,\n",
        "                                        shuffle=True,\n",
        "                                        color_mode=\"rgb\",\n",
        "                                        class_mode=\"categorical\",\n",
        "                                        #validate_filenames=True,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE))\n",
        "\n",
        "test_gen = datagen.flow_from_dataframe(dataframe= test_df,\n",
        "                                        #has_ext=False,\n",
        "                                        x_col='filepaths',\n",
        "                                        y_col='readable',\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        seed=6,\n",
        "                                        shuffle=True,\n",
        "                                        color_mode=\"rgb\",\n",
        "                                        class_mode=\"categorical\",\n",
        "                                        #validate_filenames=True,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE))\n",
        "\n",
        "validation_gen = datagen.flow_from_dataframe(dataframe= val_df,\n",
        "                                        #has_ext=False,\n",
        "                                        x_col='filepaths',\n",
        "                                        y_col='readable',\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        seed=6,\n",
        "                                        shuffle=True,\n",
        "                                        color_mode=\"rgb\",\n",
        "                                        class_mode=\"categorical\",\n",
        "                                        #validate_filenames=True,\n",
        "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3BmrpTOh2jH",
        "outputId": "ef6eddb4-eae2-4784-a18a-77e97beab697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2111 validated image filenames belonging to 2 classes.\n",
            "Found 264 validated image filenames belonging to 2 classes.\n",
            "Found 264 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# images = [train_gen[0][0][i] for i in range(16)]\n",
        "# fig, axes = plt.subplots(3, 5, figsize = (10, 10))\n",
        "\n",
        "# axes = axes.flatten()\n",
        "\n",
        "# for img, ax in zip(images, axes):\n",
        "#     ax.imshow(img.reshape(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "#     ax.axis('off')\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "dAZ48zguj3za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the Model"
      ],
      "metadata": {
        "id": "5y5omtzSkPP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet vit-keras\n",
        "\n",
        "from vit_keras import vit\n",
        "\n",
        "vit_model = vit.vit_b32(\n",
        "        image_size = IMAGE_SIZE,\n",
        "        activation = 'softmax',\n",
        "        pretrained = True,\n",
        "        include_top = False,\n",
        "        pretrained_top = False,\n",
        "        classes = 2)"
      ],
      "metadata": {
        "id": "8t03il5QkJUD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf2553ba-e510-4354-eb48-5464555740ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/faustomorales/vit-keras/releases/download/dl/ViT-B_32_imagenet21k+imagenet2012.npz\n",
            "353255424/353253686 [==============================] - 13s 0us/step\n",
            "353263616/353253686 [==============================] - 13s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "        vit_model,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(11, activation = tfa.activations.gelu),\n",
        "        tf.keras.layers.Dense(11, activation = tfa.activations.gelu),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(2, 'softmax')\n",
        "    ],\n",
        "    name = 'vision_transformer')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X5YUEU-3OHK",
        "outputId": "af9a2ab5-313e-4344-f903-0af935c727f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vision_transformer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vit-b32 (Functional)        (None, 768)               87455232  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 768)               0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 768)              3072      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 11)                8459      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 11)                132       \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 11)               44        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,466,963\n",
            "Trainable params: 87,465,405\n",
            "Non-trainable params: 1,558\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.0001\n",
        "EPOCHS = 100\n",
        "\n",
        "optimizer = tfa.optimizers.RectifiedAdam(learning_rate = learning_rate)\n",
        "\n",
        "model.compile(optimizer = optimizer, \n",
        "              loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.2), \n",
        "              metrics = ['accuracy',tf.keras.metrics.AUC(name='auc')])\n",
        "\n",
        "STEP_SIZE_TRAIN = train_gen.n // train_gen.batch_size\n",
        "STEP_SIZE_VALID = validation_gen.n // validation_gen.batch_size\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_auc',\n",
        "                                                 factor = 0.2,\n",
        "                                                 patience = 2,\n",
        "                                                 verbose = 1,\n",
        "                                                 min_delta = 1e-4,\n",
        "                                                 min_lr = 1e-6,\n",
        "                                                 mode = 'max')\n",
        "\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_auc',\n",
        "                                                 min_delta = 1e-4,\n",
        "                                                 patience = 10,\n",
        "                                                 mode = 'max',\n",
        "                                                 restore_best_weights = True,\n",
        "                                                 verbose = 1)\n",
        "\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath = './model.hdf5',\n",
        "                                                  monitor = 'val_auc', \n",
        "                                                  verbose = 1, \n",
        "                                                  save_best_only = True,\n",
        "                                                  save_weights_only = True,\n",
        "                                                  mode = 'max')\n",
        "\n",
        "callbacks = [earlystopping, reduce_lr, checkpointer]\n",
        "\n",
        "model.fit(x = train_gen,\n",
        "          steps_per_epoch = STEP_SIZE_TRAIN,\n",
        "          validation_data = validation_gen,\n",
        "          validation_steps = STEP_SIZE_VALID,\n",
        "          epochs = EPOCHS,\n",
        "          callbacks = callbacks)\n",
        "# Save the weights\n",
        "model.save_weights('./checkpoints/my_checkpoint')\n",
        "# model.save('model.h5', save_weights_only = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJpSBXop3Tb3",
        "outputId": "08c9294e-58ef-45bb-e0b2-7e4000e494c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3660 - accuracy: 0.9862 - auc: 0.9939\n",
            "Epoch 1: val_auc improved from -inf to 0.72337, saving model to ./model.hdf5\n",
            "140/140 [==============================] - 61s 266ms/step - loss: 0.3660 - accuracy: 0.9862 - auc: 0.9939 - val_loss: 0.8071 - val_accuracy: 0.7020 - val_auc: 0.7234 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3517 - accuracy: 0.9938 - auc: 0.9989\n",
            "Epoch 2: val_auc improved from 0.72337 to 0.73008, saving model to ./model.hdf5\n",
            "140/140 [==============================] - 34s 240ms/step - loss: 0.3517 - accuracy: 0.9938 - auc: 0.9989 - val_loss: 0.7823 - val_accuracy: 0.7020 - val_auc: 0.7301 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.9604 - auc: 0.9890\n",
            "Epoch 3: val_auc did not improve from 0.73008\n",
            "140/140 [==============================] - 33s 233ms/step - loss: 0.3866 - accuracy: 0.9604 - auc: 0.9890 - val_loss: 0.8750 - val_accuracy: 0.6588 - val_auc: 0.6951 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3683 - accuracy: 0.9776 - auc: 0.9923\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "\n",
            "Epoch 4: val_auc did not improve from 0.73008\n",
            "140/140 [==============================] - 33s 233ms/step - loss: 0.3683 - accuracy: 0.9776 - auc: 0.9923 - val_loss: 0.8895 - val_accuracy: 0.6941 - val_auc: 0.6998 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3495 - accuracy: 0.9943 - auc: 0.9995\n",
            "Epoch 5: val_auc did not improve from 0.73008\n",
            "140/140 [==============================] - 33s 232ms/step - loss: 0.3495 - accuracy: 0.9943 - auc: 0.9995 - val_loss: 0.8279 - val_accuracy: 0.6745 - val_auc: 0.7228 - lr: 2.0000e-05\n",
            "Epoch 6/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3451 - accuracy: 0.9971 - auc: 0.9997\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
            "\n",
            "Epoch 6: val_auc did not improve from 0.73008\n",
            "140/140 [==============================] - 33s 233ms/step - loss: 0.3451 - accuracy: 0.9971 - auc: 0.9997 - val_loss: 0.8206 - val_accuracy: 0.7059 - val_auc: 0.7270 - lr: 2.0000e-05\n",
            "Epoch 7/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3459 - accuracy: 0.9952 - auc: 0.9982\n",
            "Epoch 7: val_auc improved from 0.73008 to 0.73507, saving model to ./model.hdf5\n",
            "140/140 [==============================] - 34s 240ms/step - loss: 0.3459 - accuracy: 0.9952 - auc: 0.9982 - val_loss: 0.7977 - val_accuracy: 0.7059 - val_auc: 0.7351 - lr: 4.0000e-06\n",
            "Epoch 8/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3483 - accuracy: 0.9962 - auc: 0.9998\n",
            "Epoch 8: val_auc did not improve from 0.73507\n",
            "140/140 [==============================] - 33s 233ms/step - loss: 0.3483 - accuracy: 0.9962 - auc: 0.9998 - val_loss: 0.8507 - val_accuracy: 0.6902 - val_auc: 0.7116 - lr: 4.0000e-06\n",
            "Epoch 9/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3466 - accuracy: 0.9967 - auc: 0.9994\n",
            "Epoch 9: val_auc improved from 0.73507 to 0.73709, saving model to ./model.hdf5\n",
            "140/140 [==============================] - 34s 240ms/step - loss: 0.3466 - accuracy: 0.9967 - auc: 0.9994 - val_loss: 0.7875 - val_accuracy: 0.7176 - val_auc: 0.7371 - lr: 4.0000e-06\n",
            "Epoch 10/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3486 - accuracy: 0.9986 - auc: 1.0000\n",
            "Epoch 10: val_auc improved from 0.73709 to 0.73898, saving model to ./model.hdf5\n",
            "140/140 [==============================] - 34s 240ms/step - loss: 0.3486 - accuracy: 0.9986 - auc: 1.0000 - val_loss: 0.7936 - val_accuracy: 0.7137 - val_auc: 0.7390 - lr: 4.0000e-06\n",
            "Epoch 11/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3448 - accuracy: 0.9976 - auc: 0.9991\n",
            "Epoch 11: val_auc did not improve from 0.73898\n",
            "140/140 [==============================] - 33s 233ms/step - loss: 0.3448 - accuracy: 0.9976 - auc: 0.9991 - val_loss: 0.7963 - val_accuracy: 0.7137 - val_auc: 0.7343 - lr: 4.0000e-06\n",
            "Epoch 12/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3442 - accuracy: 0.9976 - auc: 0.9999\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\n",
            "Epoch 12: val_auc did not improve from 0.73898\n",
            "140/140 [==============================] - 33s 233ms/step - loss: 0.3442 - accuracy: 0.9976 - auc: 0.9999 - val_loss: 0.7980 - val_accuracy: 0.7137 - val_auc: 0.7318 - lr: 4.0000e-06\n",
            "Epoch 13/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3476 - accuracy: 0.9976 - auc: 0.9999\n",
            "Epoch 13: val_auc did not improve from 0.73898\n",
            "140/140 [==============================] - 33s 233ms/step - loss: 0.3476 - accuracy: 0.9976 - auc: 0.9999 - val_loss: 0.8153 - val_accuracy: 0.6980 - val_auc: 0.7272 - lr: 1.0000e-06\n",
            "Epoch 14/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3453 - accuracy: 0.9971 - auc: 0.9998\n",
            "Epoch 14: val_auc did not improve from 0.73898\n",
            "140/140 [==============================] - 33s 233ms/step - loss: 0.3453 - accuracy: 0.9971 - auc: 0.9998 - val_loss: 0.8117 - val_accuracy: 0.7020 - val_auc: 0.7296 - lr: 1.0000e-06\n",
            "Epoch 15/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3438 - accuracy: 0.9981 - auc: 0.9997\n",
            "Epoch 15: val_auc did not improve from 0.73898\n",
            "140/140 [==============================] - 33s 233ms/step - loss: 0.3438 - accuracy: 0.9981 - auc: 0.9997 - val_loss: 0.8072 - val_accuracy: 0.7137 - val_auc: 0.7284 - lr: 1.0000e-06\n",
            "Epoch 16/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3479 - accuracy: 0.9976 - auc: 0.9999\n",
            "Epoch 16: val_auc did not improve from 0.73898\n",
            "140/140 [==============================] - 33s 233ms/step - loss: 0.3479 - accuracy: 0.9976 - auc: 0.9999 - val_loss: 0.8102 - val_accuracy: 0.7020 - val_auc: 0.7292 - lr: 1.0000e-06\n",
            "Epoch 17/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3450 - accuracy: 0.9981 - auc: 0.9990\n",
            "Epoch 17: val_auc did not improve from 0.73898\n",
            "140/140 [==============================] - 33s 233ms/step - loss: 0.3450 - accuracy: 0.9981 - auc: 0.9990 - val_loss: 0.8040 - val_accuracy: 0.7020 - val_auc: 0.7324 - lr: 1.0000e-06\n",
            "Epoch 18/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3454 - accuracy: 0.9976 - auc: 0.9998\n",
            "Epoch 18: val_auc did not improve from 0.73898\n",
            "140/140 [==============================] - 33s 232ms/step - loss: 0.3454 - accuracy: 0.9976 - auc: 0.9998 - val_loss: 0.7873 - val_accuracy: 0.7216 - val_auc: 0.7366 - lr: 1.0000e-06\n",
            "Epoch 19/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3414 - accuracy: 0.9990 - auc: 0.9998\n",
            "Epoch 19: val_auc did not improve from 0.73898\n",
            "140/140 [==============================] - 33s 233ms/step - loss: 0.3414 - accuracy: 0.9990 - auc: 0.9998 - val_loss: 0.7854 - val_accuracy: 0.7216 - val_auc: 0.7370 - lr: 1.0000e-06\n",
            "Epoch 20/100\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.3466 - accuracy: 0.9986 - auc: 0.9990Restoring model weights from the end of the best epoch: 10.\n",
            "\n",
            "Epoch 20: val_auc did not improve from 0.73898\n",
            "140/140 [==============================] - 33s 234ms/step - loss: 0.3466 - accuracy: 0.9986 - auc: 0.9990 - val_loss: 0.7873 - val_accuracy: 0.7216 - val_auc: 0.7370 - lr: 1.0000e-06\n",
            "Epoch 20: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"/content/model.hdf5\")\n",
        "model.evaluate_generator(test_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsADWOY7_MnE",
        "outputId": "466b3588-f3f8-4438-81cd-e3f6e32706fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8582514524459839, 0.6590909361839294, 0.695061445236206]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_classes = np.argmax(model.predict(validation_gen, steps = validation_gen.n // validation_gen.batch_size + 1), axis = 1)\n",
        "true_classes = validation_gen.classes\n",
        "class_labels = list(validation_gen.class_indices.keys())  \n",
        "\n",
        "confusionmatrix = confusion_matrix(true_classes, predicted_classes)\n",
        "plt.figure(figsize = (16, 16))\n",
        "sns.heatmap(confusionmatrix, cmap = 'Blues', annot = True, cbar = True)\n",
        "\n",
        "print(classification_report(true_classes, predicted_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "35ayCTkW-cYw",
        "outputId": "373f1b9c-89bf-43b9-99d5-f56759e60207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.42      0.50       156\n",
            "           1       0.43      0.62      0.51       108\n",
            "\n",
            "    accuracy                           0.50       264\n",
            "   macro avg       0.52      0.52      0.50       264\n",
            "weighted avg       0.54      0.50      0.50       264\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x1152 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LiEiU4Sd60Ns"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}